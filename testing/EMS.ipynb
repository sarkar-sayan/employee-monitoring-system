{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ceafd37f-3a6d-487b-94e1-b014eb4c168a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python\n",
      "  Using cached opencv_python-4.10.0.84-cp37-abi3-win_amd64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: numpy>=1.21.2 in d:\\anaconda3\\lib\\site-packages (from opencv-python) (1.26.4)\n",
      "Using cached opencv_python-4.10.0.84-cp37-abi3-win_amd64.whl (38.8 MB)\n",
      "Installing collected packages: opencv-python\n",
      "Successfully installed opencv-python-4.10.0.84\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "346ef116-a7e3-45f6-a8b7-69ae6b24520b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dab1ea1b-c47d-43a6-9982-4710f3ac7fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1aec08d6-f762-4ca6-90a1-c712c0f9981e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pre-trained Haar cascade for face detection\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bcd1e25-a5a5-4639-8596-f5641730ea42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# frame creation in live video feed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2d0ab01d-b5e6-4489-a7ef-022d7a80e994",
   "metadata": {},
   "outputs": [],
   "source": [
    "vid = cv2.VideoCapture(0) \n",
    "  \n",
    "if not vid.isOpened():\n",
    "    raise IOError(\"Cannot open webcam\")\n",
    "\n",
    "while True: \n",
    "    # Capture the video frame by frame\n",
    "    ret, frame = vid.read()\n",
    "    \n",
    "    if not ret:  # Check if a frame was successfully read\n",
    "        print(\"Can't receive frame (stream end?). Exiting ...\")\n",
    "        break\n",
    "\n",
    "    # Define the bounding box coordinates\n",
    "    start_point = (130, 20)  # Top-left corner\n",
    "    end_point = (580, 475)    # Bottom-right corner\n",
    "    color = (255, 0, 0)       # Blue color in BGR\n",
    "    thickness = 2             # Thickness of the rectangle border\n",
    "\n",
    "    # Draw the bounding box on the frame\n",
    "    frame = cv2.rectangle(frame, start_point, end_point, color, thickness)\n",
    "\n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('frame', frame)\n",
    "    #cv2_imshow(frame)  # Uncomment if using Google Colab\n",
    "    \n",
    "    # the 'q' button is set as the \n",
    "    # quitting button you may use any \n",
    "    # desired button of your choice \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'): \n",
    "        break\n",
    "\n",
    "# After the loop release the cap object \n",
    "vid.release() \n",
    "# Destroy all the windows \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2071bb6-b6c1-4c26-ad70-87e15ce2844d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#out of frame check 1 : for 1 person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "daeb7e6b-29d9-4cdb-9f8a-1648a98052cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the webcam\n",
    "vid = cv2.VideoCapture(0)\n",
    "\n",
    "if not vid.isOpened():\n",
    "    raise IOError(\"Cannot open webcam\")\n",
    "\n",
    "while True: \n",
    "    # Capture the video frame by frame\n",
    "    ret, frame = vid.read()\n",
    "    \n",
    "    if not ret:  # Check if a frame was successfully read\n",
    "        print(\"Can't receive frame (stream end?). Exiting ...\")\n",
    "        break\n",
    "\n",
    "    # Convert the frame to grayscale for face detection\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Detect faces in the frame\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "\n",
    "    # Define the bounding box coordinates\n",
    "    start_point = (200, 20)  # Top-left corner\n",
    "    end_point = (500, 475)    # Bottom-right corner\n",
    "    color = (255, 0, 0)       # Blue color in BGR\n",
    "    thickness = 2             # Thickness of the rectangle border\n",
    "\n",
    "    # Draw the bounding box on the frame\n",
    "    frame = cv2.rectangle(frame, start_point, end_point, color, thickness)\n",
    "\n",
    "    # Check if the detected face is within the bounding box\n",
    "    face_in_frame = False\n",
    "    for (x, y, w, h) in faces:\n",
    "        if x > start_point[0] and y > start_point[1] and x + w < end_point[0] and y + h < end_point[1]:\n",
    "            face_in_frame = True\n",
    "            break\n",
    "\n",
    "    # If the face is out of the bounding box, show a prompt\n",
    "    if not face_in_frame and len(faces) > 0:\n",
    "        cv2.putText(frame, 'Out of frame', (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('frame', frame)\n",
    "    #cv2_imshow(frame)  # Uncomment if using Google Colab\n",
    "    \n",
    "    # The 'q' button is set as the quitting button\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# After the loop, release the cap object\n",
    "vid.release()\n",
    "# Destroy all the windows\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18bcd36-9609-4356-8c28-a5dc52ab819c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# out of frame check 2 : for 2 persons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c7dab080-a815-4da6-a192-8ac3ba354c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the webcam\n",
    "vid = cv2.VideoCapture(0)\n",
    "\n",
    "if not vid.isOpened():\n",
    "    raise IOError(\"Cannot open webcam\")\n",
    "\n",
    "while True: \n",
    "    # Capture the video frame by frame\n",
    "    ret, frame = vid.read()\n",
    "    \n",
    "    if not ret:  # Check if a frame was successfully read\n",
    "        print(\"Can't receive frame (stream end?). Exiting ...\")\n",
    "        break\n",
    "\n",
    "    # Convert the frame to grayscale for face detection\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Detect faces in the frame\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "\n",
    "    # Define the bounding box coordinates for two faces\n",
    "    bbox1_start = (50, 20)  # Top-left corner of first bounding box\n",
    "    bbox1_end = (300, 475)    # Bottom-right corner of first bounding box\n",
    "\n",
    "    bbox2_start = (350, 20)  # Top-left corner of second bounding box\n",
    "    bbox2_end = (600, 475)    # Bottom-right corner of second bounding box\n",
    "\n",
    "    color = (255, 0, 0)       # Blue color in BGR\n",
    "    thickness = 2             # Thickness of the rectangle border\n",
    "\n",
    "    # Draw the bounding boxes on the frame\n",
    "    frame = cv2.rectangle(frame, bbox1_start, bbox1_end, color, thickness)\n",
    "    frame = cv2.rectangle(frame, bbox2_start, bbox2_end, color, thickness)\n",
    "\n",
    "    # Initialize flags to check if faces are within their respective bounding boxes\n",
    "    face1_in_frame = False\n",
    "    face2_in_frame = False\n",
    "\n",
    "    # Check if the detected faces are within the bounding boxes\n",
    "    for (x, y, w, h) in faces:\n",
    "        if bbox1_start[0] < x < bbox1_end[0] and bbox1_start[1] < y < bbox1_end[1] and \\\n",
    "           bbox1_start[0] < x + w < bbox1_end[0] and bbox1_start[1] < y + h < bbox1_end[1]:\n",
    "            face1_in_frame = True\n",
    "        elif bbox2_start[0] < x < bbox2_end[0] and bbox2_start[1] < y < bbox2_end[1] and \\\n",
    "             bbox2_start[0] < x + w < bbox2_end[0] and bbox2_start[1] < y + h < bbox2_end[1]:\n",
    "            face2_in_frame = True\n",
    "\n",
    "    # If any face is out of the bounding boxes, show a prompt\n",
    "    if not face1_in_frame:\n",
    "        cv2.putText(frame, 'Face 1 Out of Frame', (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "    if not face2_in_frame:\n",
    "        cv2.putText(frame, 'Face 2 Out of Frame', (50, 100), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('frame', frame)\n",
    "    #cv2_imshow(frame)  # Uncomment if using Google Colab\n",
    "    \n",
    "    # The 'q' button is set as the quitting button\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# After the loop, release the cap object\n",
    "vid.release()\n",
    "# Destroy all the windows\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455b9856-cca6-487e-a7c1-38c020e5fcd1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "410bcfa5-c28d-40b9-a2d6-c040903f2686",
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.10.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\dnn\\src\\darknet\\darknet_importer.cpp:210: error: (-212:Parsing error) Failed to open NetParameter file: yolov3.cfg in function 'cv::dnn::dnn4_v20240521::readNetFromDarknet'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Load YOLO\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m net \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mdnn\u001b[38;5;241m.\u001b[39mreadNet(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myolov3.weights\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myolov3.cfg\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m layer_names \u001b[38;5;241m=\u001b[39m net\u001b[38;5;241m.\u001b[39mgetLayerNames()\n\u001b[0;32m      4\u001b[0m output_layers \u001b[38;5;241m=\u001b[39m [layer_names[i[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m net\u001b[38;5;241m.\u001b[39mgetUnconnectedOutLayers()]\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.10.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\dnn\\src\\darknet\\darknet_importer.cpp:210: error: (-212:Parsing error) Failed to open NetParameter file: yolov3.cfg in function 'cv::dnn::dnn4_v20240521::readNetFromDarknet'\n"
     ]
    }
   ],
   "source": [
    "# Load YOLO\n",
    "net = cv2.dnn.readNet(\"yolov3.weights\", \"yolov3.cfg\")\n",
    "layer_names = net.getLayerNames()\n",
    "output_layers = [layer_names[i[0] - 1] for i in net.getUnconnectedOutLayers()]\n",
    "\n",
    "# Load class names\n",
    "with open(\"coco.names\", \"r\") as f:\n",
    "    classes = [line.strip() for line in f.readlines()]\n",
    "\n",
    "# Open the webcam\n",
    "vid = cv2.VideoCapture(0)\n",
    "\n",
    "if not vid.isOpened():\n",
    "    raise IOError(\"Cannot open webcam\")\n",
    "\n",
    "while True: \n",
    "    # Capture the video frame by frame\n",
    "    ret, frame = vid.read()\n",
    "    \n",
    "    if not ret:  # Check if a frame was successfully read\n",
    "        print(\"Can't receive frame (stream end?). Exiting ...\")\n",
    "        break\n",
    "\n",
    "    height, width, channels = frame.shape\n",
    "\n",
    "    # Detecting objects\n",
    "    blob = cv2.dnn.blobFromImage(frame, 0.00392, (416, 416), (0, 0, 0), True, crop=False)\n",
    "    net.setInput(blob)\n",
    "    outs = net.forward(output_layers)\n",
    "\n",
    "    # Initialize lists for bounding boxes, confidences, and class IDs\n",
    "    class_ids = []\n",
    "    confidences = []\n",
    "    boxes = []\n",
    "\n",
    "    for out in outs:\n",
    "        for detection in out:\n",
    "            scores = detection[5:]\n",
    "            class_id = np.argmax(scores)\n",
    "            confidence = scores[class_id]\n",
    "            if classes[class_id] == \"person\" and confidence > 0.5:  # Detect only person class\n",
    "                center_x = int(detection[0] * width)\n",
    "                center_y = int(detection[1] * height)\n",
    "                w = int(detection[2] * width)\n",
    "                h = int(detection[3] * height)\n",
    "                x = int(center_x - w / 2)\n",
    "                y = int(center_y - h / 2)\n",
    "                boxes.append([x, y, w, h])\n",
    "                confidences.append(float(confidence))\n",
    "                class_ids.append(class_id)\n",
    "\n",
    "    # Non-maximum suppression to remove overlapping bounding boxes\n",
    "    indexes = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.4)\n",
    "\n",
    "    # Define the bounding box coordinates for two faces\n",
    "    bbox1_start = (100, 100)  # Top-left corner of first bounding box\n",
    "    bbox1_end = (300, 300)    # Bottom-right corner of first bounding box\n",
    "\n",
    "    bbox2_start = (350, 100)  # Top-left corner of second bounding box\n",
    "    bbox2_end = (550, 300)    # Bottom-right corner of second bounding box\n",
    "\n",
    "    color = (255, 0, 0)       # Blue color in BGR\n",
    "    thickness = 2             # Thickness of the rectangle border\n",
    "\n",
    "    # Draw the bounding boxes on the frame\n",
    "    frame = cv2.rectangle(frame, bbox1_start, bbox1_end, color, thickness)\n",
    "    frame = cv2.rectangle(frame, bbox2_start, bbox2_end, color, thickness)\n",
    "\n",
    "    # Initialize flags to check if faces are within their respective bounding boxes\n",
    "    face1_in_frame = False\n",
    "    face2_in_frame = False\n",
    "\n",
    "    for i in range(len(boxes)):\n",
    "        if i in indexes:\n",
    "            x, y, w, h = boxes[i]\n",
    "            if bbox1_start[0] < x < bbox1_end[0] and bbox1_start[1] < y < bbox1_end[1] and \\\n",
    "               bbox1_start[0] < x + w < bbox1_end[0] and bbox1_start[1] < y + h < bbox1_end[1]:\n",
    "                face1_in_frame = True\n",
    "            elif bbox2_start[0] < x < bbox2_end[0] and bbox2_start[1] < y < bbox2_end[1] and \\\n",
    "                 bbox2_start[0] < x + w < bbox2_end[0] and bbox2_start[1] < y + h < bbox2_end[1]:\n",
    "                face2_in_frame = True\n",
    "\n",
    "            # Draw bounding box for the detected face\n",
    "            frame = cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "    # If any face is out of the bounding boxes, show a prompt\n",
    "    if not face1_in_frame and len(boxes) > 0:\n",
    "        cv2.putText(frame, 'Face 1 Out of Frame', (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "    if not face2_in_frame and len(boxes) > 0:\n",
    "        cv2.putText(frame, 'Face 2 Out of Frame', (50, 100), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('frame', frame)\n",
    "    #cv2_imshow(frame)  # Uncomment if using Google Colab\n",
    "    \n",
    "    # The 'q' button is set as the quitting button\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# After the loop, release the cap object\n",
    "vid.release()\n",
    "# Destroy all the windows\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b757e8c-3801-4de8-9a18-cddda8c878a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4dc910c1-50cf-4b37-8a33-54db3f4f85a3",
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.10.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\dnn\\src\\darknet\\darknet_importer.cpp:210: error: (-212:Parsing error) Failed to open NetParameter file: yolov3.cfg in function 'cv::dnn::dnn4_v20240521::readNetFromDarknet'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Load YOLO\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m net \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mdnn\u001b[38;5;241m.\u001b[39mreadNet(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myolov3.weights\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myolov3.cfg\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m layer_names \u001b[38;5;241m=\u001b[39m net\u001b[38;5;241m.\u001b[39mgetLayerNames()\n\u001b[0;32m      4\u001b[0m output_layers \u001b[38;5;241m=\u001b[39m [layer_names[i[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m net\u001b[38;5;241m.\u001b[39mgetUnconnectedOutLayers()]\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.10.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\dnn\\src\\darknet\\darknet_importer.cpp:210: error: (-212:Parsing error) Failed to open NetParameter file: yolov3.cfg in function 'cv::dnn::dnn4_v20240521::readNetFromDarknet'\n"
     ]
    }
   ],
   "source": [
    "# Load YOLO\n",
    "net = cv2.dnn.readNet(\"yolov3.weights\", \"yolov3.cfg\")\n",
    "layer_names = net.getLayerNames()\n",
    "output_layers = [layer_names[i[0] - 1] for i in net.getUnconnectedOutLayers()]\n",
    "classes = []\n",
    "with open(\"coco.names\", \"r\") as f:\n",
    "    classes = [line.strip() for line in f.readlines()]\n",
    "\n",
    "# Define boundary boxes for desks\n",
    "desk_boundaries = {\n",
    "    \"desk1\": (50, 50, 200, 200),  # (x1, y1, x2, y2)\n",
    "    \"desk2\": (300, 50, 450, 200),\n",
    "    # Add more desks as needed\n",
    "}\n",
    "\n",
    "def draw_boundary_boxes(frame):\n",
    "    for desk, (x1, y1, x2, y2) in desk_boundaries.items():\n",
    "        cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "        cv2.putText(frame, desk, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "def is_outside_boundary(box, boundary):\n",
    "    x, y, w, h = box\n",
    "    bx1, by1, bx2, by2 = boundary\n",
    "    if x < bx1 or x + w > bx2 or y < by1 or y + h > by2:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def process_frame(frame):\n",
    "    height, width, channels = frame.shape\n",
    "    blob = cv2.dnn.blobFromImage(frame, 0.00392, (416, 416), (0, 0, 0), True, crop=False)\n",
    "    net.setInput(blob)\n",
    "    outs = net.forward(output_layers)\n",
    "\n",
    "    class_ids = []\n",
    "    confidences = []\n",
    "    boxes = []\n",
    "\n",
    "    for out in outs:\n",
    "        for detection in out:\n",
    "            scores = detection[5:]\n",
    "            class_id = np.argmax(scores)\n",
    "            confidence = scores[class_id]\n",
    "            if confidence > 0.5 and classes[class_id] == \"person\":\n",
    "                center_x = int(detection[0] * width)\n",
    "                center_y = int(detection[1] * height)\n",
    "                w = int(detection[2] * width)\n",
    "                h = int(detection[3] * height)\n",
    "                x = int(center_x - w / 2)\n",
    "                y = int(center_y - h / 2)\n",
    "                boxes.append([x, y, w, h])\n",
    "                confidences.append(float(confidence))\n",
    "                class_ids.append(class_id)\n",
    "\n",
    "    indexes = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.4)\n",
    "    for i in range(len(boxes)):\n",
    "        if i in indexes:\n",
    "            x, y, w, h = boxes[i]\n",
    "            for desk, boundary in desk_boundaries.items():\n",
    "                if is_outside_boundary((x, y, w, h), boundary):\n",
    "                    cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 0, 255), 2)\n",
    "                    cv2.putText(frame, \"Alert!\", (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)\n",
    "                else:\n",
    "                    cv2.rectangle(frame, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "\n",
    "cap = cv2.VideoCapture(0)  # Change 0 to your camera source\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    draw_boundary_boxes(frame)\n",
    "    process_frame(frame)\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cebdf331-f6dc-4ab3-89ab-7d60f604b857",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
