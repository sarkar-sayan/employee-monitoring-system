{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ceafd37f-3a6d-487b-94e1-b014eb4c168a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python\n",
      "  Using cached opencv_python-4.10.0.84-cp37-abi3-win_amd64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: numpy>=1.21.2 in d:\\anaconda3\\lib\\site-packages (from opencv-python) (1.26.4)\n",
      "Using cached opencv_python-4.10.0.84-cp37-abi3-win_amd64.whl (38.8 MB)\n",
      "Installing collected packages: opencv-python\n",
      "Successfully installed opencv-python-4.10.0.84\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "346ef116-a7e3-45f6-a8b7-69ae6b24520b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dab1ea1b-c47d-43a6-9982-4710f3ac7fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1aec08d6-f762-4ca6-90a1-c712c0f9981e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pre-trained Haar cascade for face detection\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7bcd1e25-a5a5-4639-8596-f5641730ea42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# frame creation in live video feed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d0ab01d-b5e6-4489-a7ef-022d7a80e994",
   "metadata": {},
   "outputs": [],
   "source": [
    "vid = cv2.VideoCapture(0) \n",
    "  \n",
    "if not vid.isOpened():\n",
    "    raise IOError(\"Cannot open webcam\")\n",
    "\n",
    "while True: \n",
    "    # Capture the video frame by frame\n",
    "    ret, frame = vid.read()\n",
    "    \n",
    "    if not ret:  # Check if a frame was successfully read\n",
    "        print(\"Can't receive frame (stream end?). Exiting ...\")\n",
    "        break\n",
    "\n",
    "    # Define the bounding box coordinates\n",
    "    start_point = (130, 20)  # Top-left corner\n",
    "    end_point = (580, 475)    # Bottom-right corner\n",
    "    color = (255, 0, 0)       # Blue color in BGR\n",
    "    thickness = 2             # Thickness of the rectangle border\n",
    "\n",
    "    # Draw the bounding box on the frame\n",
    "    frame = cv2.rectangle(frame, start_point, end_point, color, thickness)\n",
    "\n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('frame', frame)\n",
    "    #cv2_imshow(frame)  # Uncomment if using Google Colab\n",
    "    \n",
    "    # the 'q' button is set as the \n",
    "    # quitting button you may use any \n",
    "    # desired button of your choice \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'): \n",
    "        break\n",
    "\n",
    "# After the loop release the cap object \n",
    "vid.release() \n",
    "# Destroy all the windows \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c2071bb6-b6c1-4c26-ad70-87e15ce2844d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#out of frame check 1 : for 1 person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "daeb7e6b-29d9-4cdb-9f8a-1648a98052cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the webcam\n",
    "vid = cv2.VideoCapture(0)\n",
    "\n",
    "if not vid.isOpened():\n",
    "    raise IOError(\"Cannot open webcam\")\n",
    "\n",
    "while True: \n",
    "    # Capture the video frame by frame\n",
    "    ret, frame = vid.read()\n",
    "    \n",
    "    if not ret:  # Check if a frame was successfully read\n",
    "        print(\"Can't receive frame (stream end?). Exiting ...\")\n",
    "        break\n",
    "\n",
    "    # Convert the frame to grayscale for face detection\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Detect faces in the frame\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "\n",
    "    # Define the bounding box coordinates\n",
    "    start_point = (200, 20)  # Top-left corner\n",
    "    end_point = (500, 475)    # Bottom-right corner\n",
    "    color = (255, 0, 0)       # Blue color in BGR\n",
    "    thickness = 2             # Thickness of the rectangle border\n",
    "\n",
    "    # Draw the bounding box on the frame\n",
    "    frame = cv2.rectangle(frame, start_point, end_point, color, thickness)\n",
    "\n",
    "    # Check if the detected face is within the bounding box\n",
    "    face_in_frame = False\n",
    "    for (x, y, w, h) in faces:\n",
    "        if x > start_point[0] and y > start_point[1] and x + w < end_point[0] and y + h < end_point[1]:\n",
    "            face_in_frame = True\n",
    "            break\n",
    "\n",
    "    # If the face is out of the bounding box, show a prompt\n",
    "    if not face_in_frame and len(faces) > 0:\n",
    "        cv2.putText(frame, 'Out of frame', (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('frame', frame)\n",
    "    #cv2_imshow(frame)  # Uncomment if using Google Colab\n",
    "    \n",
    "    # The 'q' button is set as the quitting button\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# After the loop, release the cap object\n",
    "vid.release()\n",
    "# Destroy all the windows\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f18bcd36-9609-4356-8c28-a5dc52ab819c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# out of frame check 2 : for 2 persons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c7dab080-a815-4da6-a192-8ac3ba354c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the webcam\n",
    "vid = cv2.VideoCapture(0)\n",
    "\n",
    "if not vid.isOpened():\n",
    "    raise IOError(\"Cannot open webcam\")\n",
    "\n",
    "while True: \n",
    "    # Capture the video frame by frame\n",
    "    ret, frame = vid.read()\n",
    "    \n",
    "    if not ret:  # Check if a frame was successfully read\n",
    "        print(\"Can't receive frame (stream end?). Exiting ...\")\n",
    "        break\n",
    "\n",
    "    # Convert the frame to grayscale for face detection\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Detect faces in the frame\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "\n",
    "    # Define the bounding box coordinates for two faces\n",
    "    bbox1_start = (50, 20)  # Top-left corner of first bounding box\n",
    "    bbox1_end = (300, 475)    # Bottom-right corner of first bounding box\n",
    "\n",
    "    bbox2_start = (350, 20)  # Top-left corner of second bounding box\n",
    "    bbox2_end = (600, 475)    # Bottom-right corner of second bounding box\n",
    "\n",
    "    color = (255, 0, 0)       # Blue color in BGR\n",
    "    thickness = 2             # Thickness of the rectangle border\n",
    "\n",
    "    # Draw the bounding boxes on the frame\n",
    "    frame = cv2.rectangle(frame, bbox1_start, bbox1_end, color, thickness)\n",
    "    frame = cv2.rectangle(frame, bbox2_start, bbox2_end, color, thickness)\n",
    "\n",
    "    # Initialize flags to check if faces are within their respective bounding boxes\n",
    "    face1_in_frame = False\n",
    "    face2_in_frame = False\n",
    "\n",
    "    # Check if the detected faces are within the bounding boxes\n",
    "    for (x, y, w, h) in faces:\n",
    "        if bbox1_start[0] < x < bbox1_end[0] and bbox1_start[1] < y < bbox1_end[1] and \\\n",
    "           bbox1_start[0] < x + w < bbox1_end[0] and bbox1_start[1] < y + h < bbox1_end[1]:\n",
    "            face1_in_frame = True\n",
    "        elif bbox2_start[0] < x < bbox2_end[0] and bbox2_start[1] < y < bbox2_end[1] and \\\n",
    "             bbox2_start[0] < x + w < bbox2_end[0] and bbox2_start[1] < y + h < bbox2_end[1]:\n",
    "            face2_in_frame = True\n",
    "\n",
    "    # If any face is out of the bounding boxes, show a prompt\n",
    "    if not face1_in_frame:\n",
    "        cv2.putText(frame, 'Face 1 Out of Frame', (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "    if not face2_in_frame:\n",
    "        cv2.putText(frame, 'Face 2 Out of Frame', (50, 100), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('frame', frame)\n",
    "    #cv2_imshow(frame)  # Uncomment if using Google Colab\n",
    "    \n",
    "    # The 'q' button is set as the quitting button\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# After the loop, release the cap object\n",
    "vid.release()\n",
    "# Destroy all the windows\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "455b9856-cca6-487e-a7c1-38c020e5fcd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tracking trial with better model yolov3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cb48dc25-efe6-417e-b0fe-de1755a7f2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Paths to the YOLO files\n",
    "config_path = r\"C:\\Users\\champ\\Downloads\\yolov3.cfg\"\n",
    "weights_path = r\"C:\\Users\\champ\\Downloads\\yolov3.weights\"\n",
    "names_path = r\"C:\\Users\\champ\\Downloads\\coco.names\"\n",
    "\n",
    "# Check if files exist\n",
    "if not os.path.exists(config_path):\n",
    "    raise IOError(f\"Configuration file not found: {config_path}\")\n",
    "if not os.path.exists(weights_path):\n",
    "    raise IOError(f\"Weights file not found: {weights_path}\")\n",
    "if not os.path.exists(names_path):\n",
    "    raise IOError(f\"Names file not found: {names_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "151cb366-049d-4f3c-a4b3-b3afae760482",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load YOLO\n",
    "net = cv2.dnn.readNet(r\"C:\\Users\\champ\\Downloads\\yolov3.weights\", r\"C:\\Users\\champ\\Downloads\\yolov3.cfg\")\n",
    "layer_names = net.getLayerNames()\n",
    "# This part handles getting the output layers properly\n",
    "output_layers = [layer_names[i - 1] for i in net.getUnconnectedOutLayers().flatten()]\n",
    "\n",
    "\n",
    "# Load class names\n",
    "with open(r\"C:\\Users\\champ\\Downloads\\coco.names\", \"r\") as f:\n",
    "    classes = [line.strip() for line in f.readlines()]\n",
    "\n",
    "# Open the webcam\n",
    "vid = cv2.VideoCapture(0)\n",
    "\n",
    "if not vid.isOpened():\n",
    "    raise IOError(\"Cannot open webcam\")\n",
    "\n",
    "while True: \n",
    "    # Capture the video frame by frame\n",
    "    ret, frame = vid.read()\n",
    "    \n",
    "    if not ret:  # Check if a frame was successfully read\n",
    "        print(\"Can't receive frame (stream end?). Exiting ...\")\n",
    "        break\n",
    "\n",
    "    height, width, channels = frame.shape\n",
    "\n",
    "    # Detecting objects\n",
    "    blob = cv2.dnn.blobFromImage(frame, 0.00392, (416, 416), (0, 0, 0), True, crop=False)\n",
    "    net.setInput(blob)\n",
    "    outs = net.forward(output_layers)\n",
    "\n",
    "    # Initialize lists for bounding boxes, confidences, and class IDs\n",
    "    class_ids = []\n",
    "    confidences = []\n",
    "    boxes = []\n",
    "\n",
    "        # This section is for detecting objects and handling them correctly\n",
    "    for out in outs:\n",
    "        for detection in out:\n",
    "            scores = detection[5:]\n",
    "            class_id = np.argmax(scores)\n",
    "            confidence = scores[class_id]\n",
    "            if classes[class_id] == \"person\" and confidence > 0.5:  # Detect only person class\n",
    "                center_x = int(detection[0] * width)\n",
    "                center_y = int(detection[1] * height)\n",
    "                w = int(detection[2] * width)\n",
    "                h = int(detection[3] * height)\n",
    "                x = int(center_x - w / 2)\n",
    "                y = int(center_y - h / 2)\n",
    "                boxes.append([x, y, w, h])\n",
    "                confidences.append(float(confidence))\n",
    "                class_ids.append(class_id)\n",
    "\n",
    "    # Non-maximum suppression to remove overlapping bounding boxes\n",
    "    indexes = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.4)\n",
    "\n",
    "    # Draw bounding boxes and check if faces are within their respective bounding boxes\n",
    "    for i in range(len(boxes)):\n",
    "        if i in indexes:\n",
    "            x, y, w, h = boxes[i]\n",
    "            if bbox1_start[0] < x < bbox1_end[0] and bbox1_start[1] < y < bbox1_end[1] and \\\n",
    "               bbox1_start[0] < x + w < bbox1_end[0] and bbox1_start[1] < y + h < bbox1_end[1]:\n",
    "                face1_in_frame = True\n",
    "            elif bbox2_start[0] < x < bbox2_end[0] and bbox2_start[1] < y < bbox2_end[1] and \\\n",
    "                 bbox2_start[0] < x + w < bbox2_end[0] and bbox2_start[1] < y + h < bbox2_end[1]:\n",
    "                face2_in_frame = True\n",
    "    \n",
    "            # Draw bounding box for the detected face\n",
    "            frame = cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('frame', frame)\n",
    "    #cv2_imshow(frame)  # Uncomment if using Google Colab\n",
    "    \n",
    "    # The 'q' button is set as the quitting button\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# After the loop, release the cap object\n",
    "vid.release()\n",
    "# Destroy all the windows\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7b757e8c-3801-4de8-9a18-cddda8c878a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Working Alert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4dc910c1-50cf-4b37-8a33-54db3f4f85a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load YOLO\n",
    "net = cv2.dnn.readNet(r\"C:\\Users\\champ\\Downloads\\yolov3.weights\", r\"C:\\Users\\champ\\Downloads\\yolov3.cfg\")\n",
    "layer_names = net.getLayerNames()\n",
    "# This part handles getting the output layers properly\n",
    "output_layers = [layer_names[i - 1] for i in net.getUnconnectedOutLayers().flatten()]\n",
    "\n",
    "classes = []\n",
    "with open(r\"C:\\Users\\champ\\Downloads\\coco.names\", \"r\") as f:\n",
    "    classes = [line.strip() for line in f.readlines()]\n",
    "\n",
    "# Define boundary boxes for desks\n",
    "desk_boundaries = {\n",
    "    \"desk1\": (50, 20, 600, 480),  # (x1, y1, x2, y2)\n",
    "    #\"desk2\": (350, 20, 600, 480),\n",
    "    # Add more desks as needed\n",
    "}\n",
    "\n",
    "def draw_boundary_boxes(frame):\n",
    "    for desk, (x1, y1, x2, y2) in desk_boundaries.items():\n",
    "        cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "        cv2.putText(frame, desk, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "def is_outside_boundary(box, boundary):\n",
    "    x, y, w, h = box\n",
    "    bx1, by1, bx2, by2 = boundary\n",
    "    if x < bx1 or x + w > bx2 or y < by1 or y + h > by2:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def process_frame(frame):\n",
    "    height, width, channels = frame.shape\n",
    "    blob = cv2.dnn.blobFromImage(frame, 0.00392, (416, 416), (0, 0, 0), True, crop=False)\n",
    "    net.setInput(blob)\n",
    "    outs = net.forward(output_layers)\n",
    "\n",
    "    class_ids = []\n",
    "    confidences = []\n",
    "    boxes = []\n",
    "\n",
    "    for out in outs:\n",
    "        for detection in out:\n",
    "            scores = detection[5:]\n",
    "            class_id = np.argmax(scores)\n",
    "            confidence = scores[class_id]\n",
    "            if confidence > 0.5 and classes[class_id] == \"person\":\n",
    "                center_x = int(detection[0] * width)\n",
    "                center_y = int(detection[1] * height)\n",
    "                w = int(detection[2] * width)\n",
    "                h = int(detection[3] * height)\n",
    "                x = int(center_x - w / 2)\n",
    "                y = int(center_y - h / 2)\n",
    "                boxes.append([x, y, w, h])\n",
    "                confidences.append(float(confidence))\n",
    "                class_ids.append(class_id)\n",
    "\n",
    "    indexes = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.4)\n",
    "    for i in range(len(boxes)):\n",
    "        if i in indexes:\n",
    "            x, y, w, h = boxes[i]\n",
    "            for desk, boundary in desk_boundaries.items():\n",
    "                if is_outside_boundary((x, y, w, h), boundary):\n",
    "                    cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 0, 255), 2)\n",
    "                    cv2.putText(frame, \"Alert!\", (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)\n",
    "                else:\n",
    "                    cv2.rectangle(frame, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "\n",
    "cap = cv2.VideoCapture(0)  # Change 0 to your camera source\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    draw_boundary_boxes(frame)\n",
    "    process_frame(frame)\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cebdf331-f6dc-4ab3-89ab-7d60f604b857",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e24ea954-c024-476e-8605-7b02711f0f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load YOLO\n",
    "net = cv2.dnn.readNet(r\"C:\\Users\\champ\\Downloads\\yolov3.weights\", r\"C:\\Users\\champ\\Downloads\\yolov3.cfg\")\n",
    "layer_names = net.getLayerNames()\n",
    "output_layers = [layer_names[i - 1] for i in net.getUnconnectedOutLayers().flatten()]\n",
    "\n",
    "classes = []\n",
    "with open(r\"C:\\Users\\champ\\Downloads\\coco.names\", \"r\") as f:\n",
    "    classes = [line.strip() for line in f.readlines()]\n",
    "\n",
    "# Define boundary boxes for desks\n",
    "desk_boundaries = {\n",
    "    #\"desk1\": (50, 20, 600, 480),  # (x1, y1, x2, y2)\n",
    "     \"desk2\": (350, 20, 600, 480),\n",
    "    # Add more desks as needed\n",
    "}\n",
    "\n",
    "def draw_boundary_boxes(frame):\n",
    "    for desk, (x1, y1, x2, y2) in desk_boundaries.items():\n",
    "        cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "        cv2.putText(frame, desk, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "def intersection_area(rect1, rect2):\n",
    "    x1 = max(rect1[0], rect2[0])\n",
    "    y1 = max(rect1[1], rect2[1])\n",
    "    x2 = min(rect1[0] + rect1[2], rect2[0] + rect2[2])\n",
    "    y2 = min(rect1[1] + rect1[3], rect2[1] + rect2[3])\n",
    "    if x1 < x2 and y1 < y2:\n",
    "        return (x2 - x1) * (y2 - y1)\n",
    "    return 0\n",
    "\n",
    "def is_outside_boundary(box, boundary):\n",
    "    person_area = box[2] * box[3]\n",
    "    intersection = intersection_area(box, boundary)\n",
    "    inside_ratio = intersection / person_area\n",
    "    return inside_ratio < 0.2  # Less than 30% inside means more than 70% outside\n",
    "\n",
    "def process_frame(frame):\n",
    "    height, width, channels = frame.shape\n",
    "    blob = cv2.dnn.blobFromImage(frame, 0.00392, (416, 416), (0, 0, 0), True, crop=False)\n",
    "    net.setInput(blob)\n",
    "    outs = net.forward(output_layers)\n",
    "\n",
    "    class_ids = []\n",
    "    confidences = []\n",
    "    boxes = []\n",
    "\n",
    "    for out in outs:\n",
    "        for detection in out:\n",
    "            scores = detection[5:]\n",
    "            class_id = np.argmax(scores)\n",
    "            confidence = scores[class_id]\n",
    "            if confidence > 0.5 and classes[class_id] == \"person\":\n",
    "                center_x = int(detection[0] * width)\n",
    "                center_y = int(detection[1] * height)\n",
    "                w = int(detection[2] * width)\n",
    "                h = int(detection[3] * height)\n",
    "                x = int(center_x - w / 2)\n",
    "                y = int(center_y - h / 2)\n",
    "                boxes.append([x, y, w, h])\n",
    "                confidences.append(float(confidence))\n",
    "                class_ids.append(class_id)\n",
    "\n",
    "    indexes = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.4)\n",
    "    for i in range(len(boxes)):\n",
    "        if i in indexes:\n",
    "            x, y, w, h = boxes[i]\n",
    "            person_bbox = (x, y, w, h)\n",
    "            for desk, boundary in desk_boundaries.items():\n",
    "                if is_outside_boundary(person_bbox, (boundary[0], boundary[1], boundary[2] - boundary[0], boundary[3] - boundary[1])):\n",
    "                    cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 0, 255), 2)\n",
    "                    cv2.putText(frame, \"Alert!\", (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)\n",
    "                else:\n",
    "                    cv2.rectangle(frame, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "\n",
    "cap = cv2.VideoCapture(0)  # Change 0 to your camera source\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    draw_boundary_boxes(frame)\n",
    "    process_frame(frame)\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "da2873e7-846a-4dda-9e8d-a1f844f11a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using tiny-yolov3 for faster output speed and alert after time-limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "578726d2-d712-4368-b81a-c98ce3738f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# Load YOLOv3-tiny\n",
    "net = cv2.dnn.readNet(r\"C:\\Users\\champ\\Downloads\\yolov3-tiny.weights\", r\"C:\\Users\\champ\\Downloads\\yolov3-tiny.cfg\")\n",
    "layer_names = net.getLayerNames()\n",
    "output_layers = [layer_names[i - 1] for i in net.getUnconnectedOutLayers().flatten()]\n",
    "\n",
    "classes = []\n",
    "with open(r\"C:\\Users\\champ\\Downloads\\coco.names\", \"r\") as f:\n",
    "    classes = [line.strip() for line in f.readlines()]\n",
    "\n",
    "# Define boundary boxes for desks\n",
    "desk_boundaries = {\n",
    "    #\"desk1\": (50, 20, 600, 480),  # (x1, y1, x2, y2)\n",
    "     \"desk2\": (350, 20, 600, 480),\n",
    "    # Add more desks as needed\n",
    "}\n",
    "\n",
    "def draw_boundary_boxes(frame):\n",
    "    for desk, (x1, y1, x2, y2) in desk_boundaries.items():\n",
    "        cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "        cv2.putText(frame, desk, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "def intersection_area(rect1, rect2):\n",
    "    x1 = max(rect1[0], rect2[0])\n",
    "    y1 = max(rect1[1], rect2[1])\n",
    "    x2 = min(rect1[0] + rect1[2], rect2[0] + rect2[2])\n",
    "    y2 = min(rect1[1] + rect1[3], rect2[1] + rect2[3])\n",
    "    if x1 < x2 and y1 < y2:\n",
    "        return (x2 - x1) * (y2 - y1)\n",
    "    return 0\n",
    "\n",
    "def is_outside_boundary(box, boundary):\n",
    "    person_area = box[2] * box[3]\n",
    "    intersection = intersection_area(box, boundary)\n",
    "    inside_ratio = intersection / person_area\n",
    "    return inside_ratio < 0.3  # Less than 30% inside means more than 70% outside\n",
    "\n",
    "last_seen = time.time()\n",
    "alert_displayed = False\n",
    "\n",
    "def process_frame(frame):\n",
    "    global last_seen, alert_displayed\n",
    "    height, width, channels = frame.shape\n",
    "    resized_frame = cv2.resize(frame, (320, 320))  # Resize frame for faster processing\n",
    "    blob = cv2.dnn.blobFromImage(resized_frame, 0.00392, (320, 320), (0, 0, 0), True, crop=False)\n",
    "    net.setInput(blob)\n",
    "    outs = net.forward(output_layers)\n",
    "\n",
    "    class_ids = []\n",
    "    confidences = []\n",
    "    boxes = []\n",
    "\n",
    "    for out in outs:\n",
    "        for detection in out:\n",
    "            scores = detection[5:]\n",
    "            class_id = np.argmax(scores)\n",
    "            confidence = scores[class_id]\n",
    "            if confidence > 0.5 and classes[class_id] == \"person\":\n",
    "                center_x = int(detection[0] * width)\n",
    "                center_y = int(detection[1] * height)\n",
    "                w = int(detection[2] * width)\n",
    "                h = int(detection[3] * height)\n",
    "                x = int(center_x - w / 2)\n",
    "                y = int(center_y - h / 2)\n",
    "                boxes.append([x, y, w, h])\n",
    "                confidences.append(float(confidence))\n",
    "                class_ids.append(class_id)\n",
    "\n",
    "    indexes = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.4)\n",
    "    person_in_frame = False\n",
    "    \n",
    "    for i in range(len(boxes)):\n",
    "        if i in indexes:\n",
    "            x, y, w, h = boxes[i]\n",
    "            person_bbox = (x, y, w, h)\n",
    "            for desk, boundary in desk_boundaries.items():\n",
    "                if not is_outside_boundary(person_bbox, (boundary[0], boundary[1], boundary[2] - boundary[0], boundary[3] - boundary[1])):\n",
    "                    person_in_frame = True\n",
    "                    last_seen = time.time()  # Reset timer if person is detected inside the boundary\n",
    "                    alert_displayed = False\n",
    "                    cv2.rectangle(frame, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "                    break\n",
    "            if not person_in_frame:\n",
    "                cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 0, 255), 2)\n",
    "\n",
    "    if not person_in_frame:\n",
    "        if time.time() - last_seen > 5:  # 60 seconds = 1 minute\n",
    "            alert_displayed = True\n",
    "    if alert_displayed:\n",
    "        cv2.putText(frame, \"Alert: Person left for over 1 minute!\", (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "cap = cv2.VideoCapture(0)  # Change 0 to your camera source\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    draw_boundary_boxes(frame)\n",
    "    process_frame(frame)\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "95704a4b-4c4d-4f91-b56a-516ce4354b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using tiny-yolov3 for faster output speed and alert after time-limit test: multiple person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8204961-a6bb-4f7b-bcfa-a1462595775b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
